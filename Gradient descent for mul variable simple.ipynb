{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b4984ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy,math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03dbaca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array([[2104,5,1,45],[1416,3,2,40],[852,2,1,35]])\n",
    "y_train=np.array([460,232,178])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafef396",
   "metadata": {},
   "source": [
    "# Cost function of multiple variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f89c5fd",
   "metadata": {},
   "source": [
    "$$J(\\mathbf{w},b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})^2 \\tag{3}$$ \n",
    "where:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b  \\tag{4} $$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56443bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X,y,w,b):\n",
    "    m=X.shape[0]\n",
    "    cost=0.0\n",
    "    for i in range(m):\n",
    "        f_wb_i=np.dot(X[i],w)+b\n",
    "        cost=cost+(f_wb_i-y[i])**2\n",
    "    cost=cost/(2*m)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9660730d",
   "metadata": {},
   "source": [
    "# Gradient descent for multiple variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465cacc5",
   "metadata": {},
   "source": [
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\\;\n",
    "& w_j = w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{5}  \\; & \\text{for j = 0..n-1}\\newline\n",
    "&b\\ \\ = b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "\n",
    "where, n is the number of features, parameters $w_j$,  $b$, are updated simultaneously and where  \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} \\tag{6}  \\\\\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\tag{7}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cfc818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X,y,w,b):\n",
    "    m,n=X.shape\n",
    "    dj_dw=np.zeros((n,))\n",
    "    dj_db=0\n",
    "    \n",
    "    for i in range(m):\n",
    "        err=(np.dot(X[i],w)+b)-y[i]\n",
    "        for j in range(n):\n",
    "            dj_dw[j]=dj_dw[j]+err*X[i,j]\n",
    "        dj_db=dj_db+err\n",
    "    dj_dw=dj_dw/m\n",
    "    dj_db=dj_db/m\n",
    "    return dj_db,dj_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a24dc12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \n",
    "\n",
    "    w = copy.deepcopy(w_in)  #avoid modifying global w within function\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        dj_db,dj_dw = gradient_function(X, y, w, b) \n",
    "        w = w - alpha * dj_dw              \n",
    "        b = b - alpha * dj_db               \n",
    "        \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8dceac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b,w found by gradient descent: -0.00,[ 0.20396569  0.00374919 -0.0112487  -0.0658614 ] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "initial_w = [0,0,0,0]\n",
    "initial_b = 0.\n",
    "# some gradient descent settings\n",
    "iterations = 1000\n",
    "alpha = 5.0e-7\n",
    "# run gradient descent \n",
    "w_final, b_final = gradient_descent(X_train, y_train, initial_w, initial_b,\n",
    "                                                    compute_cost, compute_gradient, \n",
    "                                                    alpha, iterations)\n",
    "print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e146d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
